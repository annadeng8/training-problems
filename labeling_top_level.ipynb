{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import DistilBertTokenizer, DistilBertModel\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from io import StringIO\n",
    "from html.parser import HTMLParser\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    " \n",
    "nltk.download('stopwords')\n",
    "nltk_stopwords = set(stopwords.words('english'))\n",
    "nltk_stopwords\n",
    "\n",
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased',truncation_side='left',truncation=True)\n",
    "tokenizer.add_tokens(list(open('latex-vocabulary/latex_symbols.txt','r')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "    x = torch.ones(1, device=device)\n",
    "    print(x)\n",
    "else:\n",
    "    print(\"MPS device not found.\")\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLStripper(HTMLParser):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.reset()\n",
    "        self.strict = False\n",
    "        self.convert_charrefs= True\n",
    "        self.text = StringIO()\n",
    "    def handle_data(self, d):\n",
    "        self.text.write(d)\n",
    "    def get_data(self):\n",
    "        return self.text.getvalue()\n",
    "\n",
    "def get_latex_from_alt(context):\n",
    "    strip_deliminators = lambda latex: latex.replace('$','').replace('\\\\[','').replace('\\\\]','')\n",
    "\n",
    "    context_soup = BeautifulSoup(context)\n",
    "    latex_images = context_soup.find_all('img')\n",
    "    for image in latex_images:\n",
    "        image.replace_with(strip_deliminators(image['alt']))\n",
    "    # return [strip_deliminators(image['alt']) for image in latex_images]\n",
    "    return str(context_soup)\n",
    "\n",
    "def strip_tags(html):\n",
    "    s = MLStripper()\n",
    "    s.feed(html)\n",
    "    return s.get_data()\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    filtered_text = [w for w in text.split() if w.lower() not in nltk_stopwords]\n",
    "    return \" \".join(filtered_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Opening the JSON file where all the problems are stored:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "problems = json.load(open('amc_10_problems_with_sol.json'))\n",
    "problems[\"2015 AMC 10A #1\"][\"problem\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We must filter for problems from before 2019 and get their problem, solutions, and choices.\n",
    "\n",
    "The following functions need to be applied to the text to simplify them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "problem_text = strip_tags(get_latex_from_alt(problem))\n",
    "solutions_text = strip_tags(get_latex_from_alt(\" \".join([solution for solution in json.loads(solutions_list) if 'http' not in solution])))\n",
    "choices_text = \" \".join(json.loads(choices))\n",
    "training_text = \" \".join([problem_text, solutions_text, choices_text])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This part introduces how to apply the model to a certain string of text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DistilBERTClass(torch.nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(DistilBERTClass, self).__init__()\n",
    "        self.l1 = DistilBertModel.from_pretrained(\"distilbert-base-uncased\")\n",
    "        self.pre_classifier = torch.nn.Linear(768, 768)\n",
    "        self.dropout = torch.nn.Dropout(0.3)\n",
    "        self.classifier = torch.nn.Linear(768, num_classes)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        output_1 = self.l1(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        hidden_state = output_1[0]\n",
    "        pooler = hidden_state[:, 0]\n",
    "        pooler = self.pre_classifier(pooler)\n",
    "        pooler = torch.nn.ReLU()(pooler)\n",
    "        pooler = self.dropout(pooler)\n",
    "        return self.classifier(pooler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model must be downloaded: https://huggingface.co/iuruoy-shao/top-level-with-solutions-distilbert-amc10-2019-2022/tree/main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DistilBERTClass(num_classes=5)\n",
    "model.to(device)\n",
    "model = torch.load('top-level-with-solutions-distilbert-amc10-2019-2022.pt',map_location=device)\n",
    "\n",
    "def outputs(input_string):\n",
    "    inputs = tokenizer.encode_plus(\n",
    "            input_string,\n",
    "            None,\n",
    "            add_special_tokens=True,\n",
    "            max_length=256,\n",
    "            pad_to_max_length=True,\n",
    "            return_tensors=\"pt\").to(device)\n",
    "    fin_outputs = []\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    fin_outputs.extend(torch.sigmoid(outputs).cpu().detach().numpy().tolist())\n",
    "    outputs = np.array(fin_outputs) >= 0.5\n",
    "    return [[1 if value else 0 for value in output] for output in outputs][0]\n",
    "\n",
    "testA = \"AMC 10A\"\n",
    "testB = \"AMC 10B\"\n",
    "output = \"\";\n",
    "for year in range(2015,2019):\n",
    "    for i in range(0,2):\n",
    "        for problem_num in range(1,26):\n",
    "            if i==0:\n",
    "                problem_ind = str(year)+\" \"+testA+\" #\"+str(problem_num)\n",
    "            elif i==1:\n",
    "                problem_ind = str(year)+\" \"+testB+\" #\"+str(problem_num)\n",
    "            if (problem_ind==\"2015 AMC 10B #8\"):\n",
    "                continue\n",
    "            problem_text = strip_tags(get_latex_from_alt(problems[problem_ind][\"problem\"]))\n",
    "            solutions_text = strip_tags(get_latex_from_alt(\" \".join([solution for solution in problems[problem_ind][\"solutions\"] if 'http' not in solution])))\n",
    "            choices_text = \" \".join(problems[problem_ind][\"choices\"])\n",
    "            combined_text = remove_stopwords(\" \".join([problem_text, solutions_text, choices_text]))\n",
    "\n",
    "            assignment = outputs(combined_text)\n",
    "            if assignment==[0,0,0,0,0]:\n",
    "                assignment[0] = 1;\n",
    "            output+=problem_ind+\": \"+str(assignment)+\"\\n\"\n",
    "\n",
    "            with open('outputs_file.txt', 'w') as f:\n",
    "                f.write(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Store the outputs of every problem with their corresponding problem number / information"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
